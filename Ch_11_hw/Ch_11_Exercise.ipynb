{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8 Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I863552\\AppData\\Local\\Continuum\\anaconda3\\envs\\mlbook\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden_0_to_4 = 100\n",
    "learning_rate_0_4 = 0.01\n",
    "learning_rate_5_9 = 0.01\n",
    "\n",
    "(X_train_raw, y_train_raw), (X_test_raw, y_test_raw) = tf.keras.datasets.mnist.load_data()\n",
    "X_train_raw = X_train_raw.astype(np.float32).reshape(-1, n_inputs) / 255\n",
    "X_test_raw = X_test_raw.astype(np.float32).reshape(-1, n_inputs) / 255\n",
    "y_train_raw = y_train_raw.astype(np.int32)\n",
    "y_test_raw = y_test_raw.astype(np.int32)\n",
    "\n",
    "random_indexes_train = np.random.permutation(len(X_train_raw))\n",
    "X_train_raw = X_train_raw[random_indexes_train]\n",
    "y_train_raw = y_train_raw[random_indexes_train]\n",
    "random_indexes_test = np.random.permutation(len(X_test_raw))\n",
    "X_test = X_test_raw[random_indexes_test]\n",
    "y_test = y_test_raw[random_indexes_test]\n",
    "\n",
    "X_train = X_train_raw[5000:]\n",
    "y_train = y_train_raw[5000:]\n",
    "X_val = X_train_raw[0:5000]\n",
    "y_val = y_train_raw[0:5000]\n",
    "\n",
    "X_train_0_to_4 = X_train[y_train <= 4]\n",
    "y_train_0_to_4 = y_train[y_train <= 4]\n",
    "X_val_0_to_4 = X_val[y_val <= 4]\n",
    "y_val_0_to_4 = y_val[y_val <= 4]\n",
    "X_test_0_to_4 = X_test[y_test <= 4]\n",
    "y_test_0_to_4 = y_test[y_test <= 4]\n",
    "\n",
    "X_train_5_to_9 = X_train[y_train >= 5][:100]\n",
    "y_train_5_to_9 = y_train[y_train >= 5][:100] - 5\n",
    "X_val_5_to_9 = X_val[y_val >= 5][:30]\n",
    "y_val_5_to_9 = y_val[y_val >= 5][:30] - 5\n",
    "X_test_5_to_9 = X_test[y_test >= 5]\n",
    "y_test_5_to_9 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "def dnn(inputs, n_layers, training, n_neurons=100, activation=tf.nn.elu, initializer=he_init, batch_norm_momentum=None, name=\"\", dropout_rate=None):\n",
    "    with tf.name_scope(\"%s_dnn\" % (name)):\n",
    "        for layer in range(n_layers):\n",
    "            if (dropout_rate is not None):\n",
    "                inputs = tf.layers.dropout(inputs, dropout_rate, training=training)\n",
    "            inputs = tf.layers.dense(inputs, n_neurons, kernel_initializer=initializer, name=\"%s_hidden%d\" % (name, layer + 1))\n",
    "            if (batch_norm_momentum is not None):\n",
    "                inputs = tf.layers.batch_normalization(inputs, training=training, momentum=batch_norm_momentum)\n",
    "            inputs = activation(inputs, name=\"hidden%d_out\" % (layer + 1))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name=\"training\")\n",
    "\n",
    "with tf.name_scope(\"dnn_0_to_4\"):\n",
    "    dnn_outputs = dnn(X, n_layers=5, n_neurons=140, training=training, name=\"dnn_0_to_4\")\n",
    "    logits_0_to_4 = tf.layers.dense(dnn_outputs, 5, name=\"logits_0_to_4\", kernel_initializer=he_init)\n",
    "    \n",
    "with tf.name_scope(\"loss_0_to_4\"):\n",
    "    xentropy_0_to_4 = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_0_to_4, labels=y, name=\"xentropy_0_to_4\") \n",
    "    loss_0_to_4 = tf.reduce_mean(xentropy_0_to_4, name=\"loss_0_to_4\")\n",
    "    loss_0_to_4_summary = tf.summary.scalar(\"loss_0_to_4_summary\", loss_0_to_4)\n",
    "    \n",
    "with tf.name_scope(\"train_0_to_4\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_0_4)\n",
    "    training_op_0_to_4 = optimizer.minimize(loss_0_to_4, name=\"training_op_0_to_4\")\n",
    "    \n",
    "with tf.name_scope(\"eval_0_to_4\"):\n",
    "    y_pred_0_to_4 = tf.nn.in_top_k(logits_0_to_4, y, 1)\n",
    "    accuracy_0_to_4 = tf.reduce_mean(tf.cast(y_pred_0_to_4, tf.float32))\n",
    "    accuracy_0_to_4_summary = tf.summary.scalar(\"accuracy_0_to_4_summary\", accuracy_0_to_4)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tAccuracy: 96.59%\tLoss: 0.112043\tBest Loss: 0.112043\n",
      "1\tAccuracy: 98.02%\tLoss: 0.076041\tBest Loss: 0.076041\n",
      "2\tAccuracy: 98.17%\tLoss: 0.070869\tBest Loss: 0.070869\n",
      "3\tAccuracy: 98.02%\tLoss: 0.080411\tBest Loss: 0.070869\n",
      "4\tAccuracy: 98.25%\tLoss: 0.059391\tBest Loss: 0.059391\n",
      "5\tAccuracy: 98.69%\tLoss: 0.051953\tBest Loss: 0.051953\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 500\n",
    "early_stoping_threshold = 20\n",
    "best_loss = np.infty\n",
    "steps_from_best_loss = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(len(X_train_0_to_4) // batch_size):\n",
    "            rdm_idx = np.random.permutation(len(X_train_0_to_4))\n",
    "            X_batch, y_batch = X_train_0_to_4[rdm_idx[:batch_size]], y_train_0_to_4[rdm_idx[:batch_size]]\n",
    "            sess.run(training_op_0_to_4, feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        loss_0_to_4_val, accuracy_0_to_4_val = sess.run([loss_0_to_4, accuracy_0_to_4], feed_dict={X: X_val_0_to_4, y: y_val_0_to_4})\n",
    "        \n",
    "        if (loss_0_to_4_val < best_loss):\n",
    "            saver.save(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "            best_loss = loss_0_to_4_val\n",
    "            steps_from_best_loss = 0\n",
    "        else:\n",
    "            steps_from_best_loss += 1\n",
    "            \n",
    "        if (steps_from_best_loss >= early_stoping_threshold):\n",
    "            print(\"Early Stopping!\")\n",
    "            break;\n",
    "\n",
    "        print(\"{}\\tAccuracy: {:.2f}%\\tLoss: {:.6f}\\tBest Loss: {:.6f}\".format(epoch, accuracy_0_to_4_val * 100, loss_0_to_4_val, best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "    accuracy_0_to_4_test = sess.run(accuracy_0_to_4, feed_dict={X: X_test_0_to_4, y: y_test_0_to_4})\n",
    "    print(\"Accuracy for test: {:.2f}%\".format(accuracy_0_to_4_test*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name=\"training\")\n",
    "\n",
    "with tf.name_scope(\"dnn_0_to_4_bn\"):\n",
    "    dnn_outputs_bn = dnn(X, n_layers=5, n_neurons=140, training=training, batch_norm_momentum=0.99, name=\"dnn_0_to_4_bn\")\n",
    "    logits_0_to_4_bn = tf.layers.dense(dnn_outputs_bn, 5, name=\"logits_0_to_4_bn\", kernel_initializer=he_init)\n",
    "    \n",
    "with tf.name_scope(\"loss_0_to_4_bn\"):\n",
    "    xentropy_0_to_4_bn = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_0_to_4_bn, labels=y, name=\"xentropy_0_to_4_bn\") \n",
    "    loss_0_to_4_bn = tf.reduce_mean(xentropy_0_to_4_bn, name=\"loss_0_to_4_bn\")\n",
    "    loss_0_to_4_summary_bn = tf.summary.scalar(\"loss_0_to_4_summary_bn\", loss_0_to_4_bn)\n",
    "    \n",
    "with tf.name_scope(\"train_0_to_4_bn\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_0_4)\n",
    "    training_op_0_to_4_bn = optimizer.minimize(loss_0_to_4_bn, name=\"training_op_0_to_4_bn\")\n",
    "    \n",
    "with tf.name_scope(\"eval_0_to_4_bn\"):\n",
    "    y_pred_0_to_4_bn = tf.nn.in_top_k(logits_0_to_4_bn, y, 1)\n",
    "    accuracy_0_to_4_bn = tf.reduce_mean(tf.cast(y_pred_0_to_4_bn, tf.float32))\n",
    "    accuracy_0_to_4_summary_bn = tf.summary.scalar(\"accuracy_0_to_4_summary_bn\", accuracy_0_to_4_bn)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tAccuracy: 97.08%\tLoss: 0.212742\tBest Loss: 0.212742\n",
      "1\tAccuracy: 97.47%\tLoss: 0.101429\tBest Loss: 0.101429\n",
      "2\tAccuracy: 97.51%\tLoss: 0.116535\tBest Loss: 0.101429\n",
      "3\tAccuracy: 98.33%\tLoss: 0.062070\tBest Loss: 0.062070\n",
      "4\tAccuracy: 98.33%\tLoss: 0.072230\tBest Loss: 0.062070\n",
      "5\tAccuracy: 98.17%\tLoss: 0.076383\tBest Loss: 0.062070\n",
      "6\tAccuracy: 98.44%\tLoss: 0.050841\tBest Loss: 0.050841\n",
      "7\tAccuracy: 98.37%\tLoss: 0.073162\tBest Loss: 0.050841\n",
      "8\tAccuracy: 98.91%\tLoss: 0.050356\tBest Loss: 0.050356\n",
      "9\tAccuracy: 97.98%\tLoss: 0.103679\tBest Loss: 0.050356\n",
      "10\tAccuracy: 98.48%\tLoss: 0.067878\tBest Loss: 0.050356\n",
      "11\tAccuracy: 98.64%\tLoss: 0.050112\tBest Loss: 0.050112\n",
      "12\tAccuracy: 99.03%\tLoss: 0.044172\tBest Loss: 0.044172\n",
      "13\tAccuracy: 98.29%\tLoss: 0.081067\tBest Loss: 0.044172\n",
      "14\tAccuracy: 98.25%\tLoss: 0.078278\tBest Loss: 0.044172\n",
      "15\tAccuracy: 98.76%\tLoss: 0.071035\tBest Loss: 0.044172\n",
      "16\tAccuracy: 98.33%\tLoss: 0.074129\tBest Loss: 0.044172\n",
      "17\tAccuracy: 98.68%\tLoss: 0.056202\tBest Loss: 0.044172\n",
      "18\tAccuracy: 98.21%\tLoss: 0.091383\tBest Loss: 0.044172\n",
      "19\tAccuracy: 98.68%\tLoss: 0.079837\tBest Loss: 0.044172\n",
      "20\tAccuracy: 98.99%\tLoss: 0.049243\tBest Loss: 0.044172\n",
      "21\tAccuracy: 98.87%\tLoss: 0.060886\tBest Loss: 0.044172\n",
      "22\tAccuracy: 98.64%\tLoss: 0.066395\tBest Loss: 0.044172\n",
      "23\tAccuracy: 98.91%\tLoss: 0.068072\tBest Loss: 0.044172\n",
      "24\tAccuracy: 98.91%\tLoss: 0.048897\tBest Loss: 0.044172\n",
      "25\tAccuracy: 98.56%\tLoss: 0.073092\tBest Loss: 0.044172\n",
      "26\tAccuracy: 98.21%\tLoss: 0.094131\tBest Loss: 0.044172\n",
      "27\tAccuracy: 98.68%\tLoss: 0.076302\tBest Loss: 0.044172\n",
      "28\tAccuracy: 98.68%\tLoss: 0.078897\tBest Loss: 0.044172\n",
      "29\tAccuracy: 98.83%\tLoss: 0.058129\tBest Loss: 0.044172\n",
      "30\tAccuracy: 99.07%\tLoss: 0.042443\tBest Loss: 0.042443\n",
      "31\tAccuracy: 98.76%\tLoss: 0.076198\tBest Loss: 0.042443\n",
      "32\tAccuracy: 99.07%\tLoss: 0.056439\tBest Loss: 0.042443\n",
      "33\tAccuracy: 98.83%\tLoss: 0.056795\tBest Loss: 0.042443\n",
      "34\tAccuracy: 99.07%\tLoss: 0.056426\tBest Loss: 0.042443\n",
      "35\tAccuracy: 98.91%\tLoss: 0.057735\tBest Loss: 0.042443\n",
      "36\tAccuracy: 98.91%\tLoss: 0.057288\tBest Loss: 0.042443\n",
      "37\tAccuracy: 98.29%\tLoss: 0.109979\tBest Loss: 0.042443\n",
      "38\tAccuracy: 99.03%\tLoss: 0.059917\tBest Loss: 0.042443\n",
      "39\tAccuracy: 98.91%\tLoss: 0.064954\tBest Loss: 0.042443\n",
      "40\tAccuracy: 98.79%\tLoss: 0.072164\tBest Loss: 0.042443\n",
      "41\tAccuracy: 99.07%\tLoss: 0.070341\tBest Loss: 0.042443\n",
      "42\tAccuracy: 99.03%\tLoss: 0.056154\tBest Loss: 0.042443\n",
      "43\tAccuracy: 99.07%\tLoss: 0.055129\tBest Loss: 0.042443\n",
      "44\tAccuracy: 98.99%\tLoss: 0.051461\tBest Loss: 0.042443\n",
      "45\tAccuracy: 98.99%\tLoss: 0.046623\tBest Loss: 0.042443\n",
      "46\tAccuracy: 99.07%\tLoss: 0.051828\tBest Loss: 0.042443\n",
      "47\tAccuracy: 99.11%\tLoss: 0.050021\tBest Loss: 0.042443\n",
      "48\tAccuracy: 98.76%\tLoss: 0.065982\tBest Loss: 0.042443\n",
      "49\tAccuracy: 98.87%\tLoss: 0.059668\tBest Loss: 0.042443\n",
      "Early Stopping!\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 500\n",
    "early_stoping_threshold = 20\n",
    "best_loss = np.infty\n",
    "steps_from_best_loss = 0\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(len(X_train_0_to_4) // batch_size):\n",
    "            rdm_idx = np.random.permutation(len(X_train_0_to_4))\n",
    "            X_batch, y_batch = X_train_0_to_4[rdm_idx[:batch_size]], y_train_0_to_4[rdm_idx[:batch_size]]\n",
    "            sess.run([training_op_0_to_4_bn, extra_update_ops], feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "        \n",
    "        loss_0_to_4_val, accuracy_0_to_4_val = sess.run([loss_0_to_4_bn, accuracy_0_to_4_bn], feed_dict={X: X_val_0_to_4, y: y_val_0_to_4})\n",
    "        \n",
    "        if (loss_0_to_4_val < best_loss):\n",
    "            saver.save(sess, \"./my_mnist_model_0_to_4_bn.ckpt\")\n",
    "            best_loss = loss_0_to_4_val\n",
    "            steps_from_best_loss = 0\n",
    "        else:\n",
    "            steps_from_best_loss += 1\n",
    "            \n",
    "        if (steps_from_best_loss >= early_stoping_threshold):\n",
    "            print(\"Early Stopping!\")\n",
    "            break;\n",
    "\n",
    "        print(\"{}\\tAccuracy: {:.2f}%\\tLoss: {:.6f}\\tBest Loss: {:.6f}\".format(epoch, accuracy_0_to_4_val * 100, loss_0_to_4_val, best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_0_to_4_bn.ckpt\n",
      "Accuracy for test: 99.16%\n",
      "Accuracy for training: 99.97%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_mnist_model_0_to_4_bn.ckpt\")\n",
    "    accuracy_0_to_4_bn_test = sess.run(accuracy_0_to_4_bn, feed_dict={X: X_test_0_to_4, y: y_test_0_to_4})\n",
    "    print(\"Accuracy for test: {:.2f}%\".format(accuracy_0_to_4_bn_test*100))\n",
    "    accuracy_0_to_4_bn_train = sess.run(accuracy_0_to_4_bn, feed_dict={X: X_train_0_to_4, y: y_train_0_to_4})\n",
    "    print(\"Accuracy for training: {:.2f}%\".format(accuracy_0_to_4_bn_train*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems we are overfitting as training set accuracy is higher than test set accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name=\"training\")\n",
    "\n",
    "with tf.name_scope(\"dnn_0_to_4_dropout\"):\n",
    "    dnn_outputs_dropout = dnn(X, n_layers=5, n_neurons=140, training=training, batch_norm_momentum=0.99, name=\"dnn_0_to_4_dropout\", dropout_rate=0.5)\n",
    "    logits_0_to_4_dropout = tf.layers.dense(dnn_outputs_dropout, 5, name=\"logits_0_to_4_dropout\", kernel_initializer=he_init)\n",
    "    \n",
    "with tf.name_scope(\"loss_0_to_4_dropout\"):\n",
    "    xentropy_0_to_4_dropout = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_0_to_4_dropout, labels=y, name=\"xentropy_0_to_4_dropout\") \n",
    "    loss_0_to_4_dropout = tf.reduce_mean(xentropy_0_to_4_dropout, name=\"loss_0_to_4_dropout\")\n",
    "    \n",
    "with tf.name_scope(\"train_0_to_4_dropout\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_0_4)\n",
    "    training_op_0_to_4_dropout = optimizer.minimize(loss_0_to_4_dropout, name=\"training_op_0_to_4_dropout\")\n",
    "    \n",
    "with tf.name_scope(\"eval_0_to_4_dropout\"):\n",
    "    y_pred_0_to_4_dropout = tf.nn.in_top_k(logits_0_to_4_dropout, y, 1)\n",
    "    accuracy_0_to_4_dropout = tf.reduce_mean(tf.cast(y_pred_0_to_4_dropout, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tAccuracy: 96.42%\tLoss: 0.341176\tBest Loss: 0.341176\n",
      "1\tAccuracy: 97.12%\tLoss: 0.171205\tBest Loss: 0.171205\n",
      "2\tAccuracy: 97.20%\tLoss: 0.141679\tBest Loss: 0.141679\n",
      "3\tAccuracy: 97.40%\tLoss: 0.126951\tBest Loss: 0.126951\n",
      "4\tAccuracy: 97.59%\tLoss: 0.099626\tBest Loss: 0.099626\n",
      "5\tAccuracy: 97.82%\tLoss: 0.086024\tBest Loss: 0.086024\n",
      "6\tAccuracy: 98.09%\tLoss: 0.077669\tBest Loss: 0.077669\n",
      "7\tAccuracy: 97.98%\tLoss: 0.072782\tBest Loss: 0.072782\n",
      "8\tAccuracy: 98.06%\tLoss: 0.069851\tBest Loss: 0.069851\n",
      "9\tAccuracy: 97.90%\tLoss: 0.077855\tBest Loss: 0.069851\n",
      "10\tAccuracy: 97.90%\tLoss: 0.066210\tBest Loss: 0.066210\n",
      "11\tAccuracy: 97.90%\tLoss: 0.072184\tBest Loss: 0.066210\n",
      "12\tAccuracy: 98.48%\tLoss: 0.059408\tBest Loss: 0.059408\n",
      "13\tAccuracy: 98.33%\tLoss: 0.061974\tBest Loss: 0.059408\n",
      "14\tAccuracy: 98.52%\tLoss: 0.055014\tBest Loss: 0.055014\n",
      "15\tAccuracy: 98.52%\tLoss: 0.059049\tBest Loss: 0.055014\n",
      "16\tAccuracy: 98.60%\tLoss: 0.054451\tBest Loss: 0.054451\n",
      "17\tAccuracy: 98.64%\tLoss: 0.053936\tBest Loss: 0.053936\n",
      "18\tAccuracy: 98.60%\tLoss: 0.054839\tBest Loss: 0.053936\n",
      "19\tAccuracy: 98.64%\tLoss: 0.053231\tBest Loss: 0.053231\n",
      "20\tAccuracy: 98.48%\tLoss: 0.054167\tBest Loss: 0.053231\n",
      "21\tAccuracy: 98.44%\tLoss: 0.060256\tBest Loss: 0.053231\n",
      "22\tAccuracy: 98.91%\tLoss: 0.047203\tBest Loss: 0.047203\n",
      "23\tAccuracy: 98.68%\tLoss: 0.050815\tBest Loss: 0.047203\n",
      "24\tAccuracy: 98.72%\tLoss: 0.046495\tBest Loss: 0.046495\n",
      "25\tAccuracy: 98.76%\tLoss: 0.046327\tBest Loss: 0.046327\n",
      "26\tAccuracy: 98.76%\tLoss: 0.047632\tBest Loss: 0.046327\n",
      "27\tAccuracy: 98.48%\tLoss: 0.051728\tBest Loss: 0.046327\n",
      "28\tAccuracy: 98.91%\tLoss: 0.043900\tBest Loss: 0.043900\n",
      "29\tAccuracy: 98.95%\tLoss: 0.041182\tBest Loss: 0.041182\n",
      "30\tAccuracy: 98.72%\tLoss: 0.047479\tBest Loss: 0.041182\n",
      "31\tAccuracy: 98.79%\tLoss: 0.042731\tBest Loss: 0.041182\n",
      "32\tAccuracy: 98.72%\tLoss: 0.046497\tBest Loss: 0.041182\n",
      "33\tAccuracy: 98.76%\tLoss: 0.044902\tBest Loss: 0.041182\n",
      "34\tAccuracy: 98.87%\tLoss: 0.044513\tBest Loss: 0.041182\n",
      "35\tAccuracy: 98.91%\tLoss: 0.043227\tBest Loss: 0.041182\n",
      "36\tAccuracy: 98.95%\tLoss: 0.040190\tBest Loss: 0.040190\n",
      "37\tAccuracy: 98.79%\tLoss: 0.044554\tBest Loss: 0.040190\n",
      "38\tAccuracy: 98.95%\tLoss: 0.043666\tBest Loss: 0.040190\n",
      "39\tAccuracy: 98.87%\tLoss: 0.041570\tBest Loss: 0.040190\n",
      "40\tAccuracy: 98.83%\tLoss: 0.041898\tBest Loss: 0.040190\n",
      "41\tAccuracy: 98.99%\tLoss: 0.038262\tBest Loss: 0.038262\n",
      "42\tAccuracy: 98.91%\tLoss: 0.039766\tBest Loss: 0.038262\n",
      "43\tAccuracy: 99.07%\tLoss: 0.034987\tBest Loss: 0.034987\n",
      "44\tAccuracy: 99.03%\tLoss: 0.038453\tBest Loss: 0.034987\n",
      "45\tAccuracy: 98.99%\tLoss: 0.038601\tBest Loss: 0.034987\n",
      "46\tAccuracy: 98.87%\tLoss: 0.038199\tBest Loss: 0.034987\n",
      "47\tAccuracy: 98.91%\tLoss: 0.043434\tBest Loss: 0.034987\n",
      "48\tAccuracy: 98.91%\tLoss: 0.040240\tBest Loss: 0.034987\n",
      "49\tAccuracy: 98.76%\tLoss: 0.042695\tBest Loss: 0.034987\n",
      "50\tAccuracy: 98.99%\tLoss: 0.036064\tBest Loss: 0.034987\n",
      "51\tAccuracy: 98.83%\tLoss: 0.040038\tBest Loss: 0.034987\n",
      "52\tAccuracy: 98.87%\tLoss: 0.039639\tBest Loss: 0.034987\n",
      "53\tAccuracy: 98.79%\tLoss: 0.040420\tBest Loss: 0.034987\n",
      "54\tAccuracy: 99.03%\tLoss: 0.038141\tBest Loss: 0.034987\n",
      "55\tAccuracy: 99.11%\tLoss: 0.037450\tBest Loss: 0.034987\n",
      "56\tAccuracy: 98.95%\tLoss: 0.038533\tBest Loss: 0.034987\n",
      "57\tAccuracy: 98.83%\tLoss: 0.036776\tBest Loss: 0.034987\n",
      "58\tAccuracy: 98.95%\tLoss: 0.034725\tBest Loss: 0.034725\n",
      "59\tAccuracy: 98.87%\tLoss: 0.037558\tBest Loss: 0.034725\n",
      "60\tAccuracy: 98.91%\tLoss: 0.037242\tBest Loss: 0.034725\n",
      "61\tAccuracy: 98.91%\tLoss: 0.036612\tBest Loss: 0.034725\n",
      "62\tAccuracy: 98.91%\tLoss: 0.035678\tBest Loss: 0.034725\n",
      "63\tAccuracy: 99.03%\tLoss: 0.034698\tBest Loss: 0.034698\n",
      "64\tAccuracy: 99.03%\tLoss: 0.034063\tBest Loss: 0.034063\n",
      "65\tAccuracy: 99.14%\tLoss: 0.033447\tBest Loss: 0.033447\n",
      "66\tAccuracy: 99.11%\tLoss: 0.033586\tBest Loss: 0.033447\n",
      "67\tAccuracy: 99.03%\tLoss: 0.034764\tBest Loss: 0.033447\n",
      "68\tAccuracy: 98.95%\tLoss: 0.035191\tBest Loss: 0.033447\n",
      "69\tAccuracy: 98.87%\tLoss: 0.037705\tBest Loss: 0.033447\n",
      "70\tAccuracy: 98.91%\tLoss: 0.036508\tBest Loss: 0.033447\n",
      "71\tAccuracy: 99.03%\tLoss: 0.033926\tBest Loss: 0.033447\n",
      "72\tAccuracy: 99.07%\tLoss: 0.032197\tBest Loss: 0.032197\n",
      "73\tAccuracy: 99.22%\tLoss: 0.032097\tBest Loss: 0.032097\n",
      "74\tAccuracy: 98.95%\tLoss: 0.034191\tBest Loss: 0.032097\n",
      "75\tAccuracy: 99.11%\tLoss: 0.037033\tBest Loss: 0.032097\n",
      "76\tAccuracy: 99.11%\tLoss: 0.034563\tBest Loss: 0.032097\n",
      "77\tAccuracy: 98.91%\tLoss: 0.035421\tBest Loss: 0.032097\n",
      "78\tAccuracy: 98.95%\tLoss: 0.036620\tBest Loss: 0.032097\n",
      "79\tAccuracy: 98.99%\tLoss: 0.032856\tBest Loss: 0.032097\n",
      "80\tAccuracy: 98.83%\tLoss: 0.037300\tBest Loss: 0.032097\n",
      "81\tAccuracy: 98.95%\tLoss: 0.033682\tBest Loss: 0.032097\n",
      "82\tAccuracy: 98.91%\tLoss: 0.039943\tBest Loss: 0.032097\n",
      "83\tAccuracy: 99.07%\tLoss: 0.034925\tBest Loss: 0.032097\n",
      "84\tAccuracy: 99.11%\tLoss: 0.036296\tBest Loss: 0.032097\n",
      "85\tAccuracy: 99.11%\tLoss: 0.033979\tBest Loss: 0.032097\n",
      "86\tAccuracy: 99.18%\tLoss: 0.031968\tBest Loss: 0.031968\n",
      "87\tAccuracy: 99.11%\tLoss: 0.033961\tBest Loss: 0.031968\n",
      "88\tAccuracy: 99.03%\tLoss: 0.033386\tBest Loss: 0.031968\n",
      "89\tAccuracy: 99.03%\tLoss: 0.035055\tBest Loss: 0.031968\n",
      "90\tAccuracy: 98.87%\tLoss: 0.038412\tBest Loss: 0.031968\n",
      "91\tAccuracy: 99.18%\tLoss: 0.033436\tBest Loss: 0.031968\n",
      "92\tAccuracy: 99.07%\tLoss: 0.033989\tBest Loss: 0.031968\n",
      "93\tAccuracy: 99.14%\tLoss: 0.033844\tBest Loss: 0.031968\n",
      "94\tAccuracy: 99.14%\tLoss: 0.031747\tBest Loss: 0.031747\n",
      "95\tAccuracy: 98.99%\tLoss: 0.033496\tBest Loss: 0.031747\n",
      "96\tAccuracy: 99.03%\tLoss: 0.035795\tBest Loss: 0.031747\n",
      "97\tAccuracy: 99.14%\tLoss: 0.033453\tBest Loss: 0.031747\n",
      "98\tAccuracy: 98.95%\tLoss: 0.037058\tBest Loss: 0.031747\n",
      "99\tAccuracy: 99.14%\tLoss: 0.033750\tBest Loss: 0.031747\n",
      "100\tAccuracy: 99.03%\tLoss: 0.037239\tBest Loss: 0.031747\n",
      "101\tAccuracy: 99.18%\tLoss: 0.031503\tBest Loss: 0.031503\n",
      "102\tAccuracy: 99.30%\tLoss: 0.030571\tBest Loss: 0.030571\n",
      "103\tAccuracy: 99.30%\tLoss: 0.031630\tBest Loss: 0.030571\n",
      "104\tAccuracy: 99.18%\tLoss: 0.029608\tBest Loss: 0.029608\n",
      "105\tAccuracy: 99.11%\tLoss: 0.031464\tBest Loss: 0.029608\n",
      "106\tAccuracy: 99.11%\tLoss: 0.034521\tBest Loss: 0.029608\n",
      "107\tAccuracy: 99.03%\tLoss: 0.035647\tBest Loss: 0.029608\n",
      "108\tAccuracy: 99.18%\tLoss: 0.031868\tBest Loss: 0.029608\n",
      "109\tAccuracy: 99.07%\tLoss: 0.034973\tBest Loss: 0.029608\n",
      "110\tAccuracy: 99.22%\tLoss: 0.032319\tBest Loss: 0.029608\n",
      "111\tAccuracy: 99.18%\tLoss: 0.032042\tBest Loss: 0.029608\n",
      "112\tAccuracy: 99.11%\tLoss: 0.032794\tBest Loss: 0.029608\n",
      "113\tAccuracy: 99.14%\tLoss: 0.029837\tBest Loss: 0.029608\n",
      "114\tAccuracy: 99.11%\tLoss: 0.030597\tBest Loss: 0.029608\n",
      "115\tAccuracy: 99.11%\tLoss: 0.030916\tBest Loss: 0.029608\n",
      "116\tAccuracy: 99.14%\tLoss: 0.030633\tBest Loss: 0.029608\n",
      "117\tAccuracy: 99.07%\tLoss: 0.032449\tBest Loss: 0.029608\n",
      "118\tAccuracy: 99.26%\tLoss: 0.031254\tBest Loss: 0.029608\n",
      "119\tAccuracy: 98.95%\tLoss: 0.034962\tBest Loss: 0.029608\n",
      "120\tAccuracy: 98.99%\tLoss: 0.034192\tBest Loss: 0.029608\n",
      "121\tAccuracy: 99.11%\tLoss: 0.032119\tBest Loss: 0.029608\n",
      "122\tAccuracy: 99.07%\tLoss: 0.030831\tBest Loss: 0.029608\n",
      "123\tAccuracy: 99.07%\tLoss: 0.033143\tBest Loss: 0.029608\n",
      "Early Stopping!\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 500\n",
    "early_stoping_threshold = 20\n",
    "best_loss = np.infty\n",
    "steps_from_best_loss = 0\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(len(X_train_0_to_4) // batch_size):\n",
    "            rdm_idx = np.random.permutation(len(X_train_0_to_4))\n",
    "            X_batch, y_batch = X_train_0_to_4[rdm_idx[:batch_size]], y_train_0_to_4[rdm_idx[:batch_size]]\n",
    "            sess.run([training_op_0_to_4_dropout, extra_update_ops], feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "        \n",
    "        loss_0_to_4_val, accuracy_0_to_4_val = sess.run([loss_0_to_4_dropout, accuracy_0_to_4_dropout], feed_dict={X: X_val_0_to_4, y: y_val_0_to_4})\n",
    "        \n",
    "        if (loss_0_to_4_val < best_loss):\n",
    "            saver.save(sess, \"./my_mnist_model_0_to_4_dropout.ckpt\")\n",
    "            best_loss = loss_0_to_4_val\n",
    "            steps_from_best_loss = 0\n",
    "        else:\n",
    "            steps_from_best_loss += 1\n",
    "            \n",
    "        if (steps_from_best_loss >= early_stoping_threshold):\n",
    "            print(\"Early Stopping!\")\n",
    "            break;\n",
    "\n",
    "        print(\"{}\\tAccuracy: {:.2f}%\\tLoss: {:.6f}\\tBest Loss: {:.6f}\".format(epoch, accuracy_0_to_4_val * 100, loss_0_to_4_val, best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_0_to_4_dropout.ckpt\n",
      "Accuracy for test: 99.42%\n",
      "Accuracy for training: 99.64%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_mnist_model_0_to_4_dropout.ckpt\")\n",
    "    accuracy_0_to_4_dropout_test = sess.run(accuracy_0_to_4_dropout, feed_dict={X: X_test_0_to_4, y: y_test_0_to_4})\n",
    "    print(\"Accuracy for test: {:.2f}%\".format(accuracy_0_to_4_dropout_test*100))\n",
    "    accuracy_0_to_4_dropout_train = sess.run(accuracy_0_to_4_dropout, feed_dict={X: X_train_0_to_4, y: y_train_0_to_4})\n",
    "    print(\"Accuracy for training: {:.2f}%\".format(accuracy_0_to_4_dropout_train*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./my_mnist_model_0_to_4_bn.ckpt.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "# DNN\n",
    "hidden_5_to_9 = tf.get_default_graph().get_tensor_by_name(\"dnn_0_to_4_bn/dnn_0_to_4_bn_dnn/hidden5_out:0\")\n",
    "logits_5_to_9 = tf.layers.dense(hidden_5_to_9, 5, name=\"logits_5_to_9\", kernel_initializer=he_init)\n",
    "\n",
    "# Loss\n",
    "xentropy_5_to_9 = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_5_to_9, labels=y)\n",
    "loss_5_to_9 = tf.reduce_mean(xentropy_5_to_9, name=\"loss_5_to_9\")\n",
    "\n",
    "# Train\n",
    "trainable_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"logits_5_to_9\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_5_9)\n",
    "training_op_5_to_9 = optimizer.minimize(loss_5_to_9, var_list=trainable_variables, name=\"training_op_5_to_9\")\n",
    "\n",
    "# Eval\n",
    "correct = tf.nn.in_top_k(logits_5_to_9, y, 1)\n",
    "accuracy_5_to_9 = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy_5_to_9\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver_5_to_9 = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_0_to_4_bn.ckpt\n",
      "0\tAccuracy: 43.33%\tLoss: 1.503489\tBest Loss: 1.503489\n",
      "1\tAccuracy: 50.00%\tLoss: 1.350548\tBest Loss: 1.350548\n",
      "2\tAccuracy: 56.67%\tLoss: 1.161270\tBest Loss: 1.161270\n",
      "3\tAccuracy: 53.33%\tLoss: 1.181116\tBest Loss: 1.161270\n",
      "4\tAccuracy: 50.00%\tLoss: 1.272534\tBest Loss: 1.161270\n",
      "5\tAccuracy: 56.67%\tLoss: 1.246152\tBest Loss: 1.161270\n",
      "6\tAccuracy: 43.33%\tLoss: 1.233158\tBest Loss: 1.161270\n",
      "7\tAccuracy: 53.33%\tLoss: 1.093383\tBest Loss: 1.093383\n",
      "8\tAccuracy: 50.00%\tLoss: 1.023241\tBest Loss: 1.023241\n",
      "9\tAccuracy: 43.33%\tLoss: 1.049706\tBest Loss: 1.023241\n",
      "10\tAccuracy: 60.00%\tLoss: 1.087927\tBest Loss: 1.023241\n",
      "11\tAccuracy: 60.00%\tLoss: 1.093096\tBest Loss: 1.023241\n",
      "12\tAccuracy: 60.00%\tLoss: 1.005928\tBest Loss: 1.005928\n",
      "13\tAccuracy: 60.00%\tLoss: 0.977106\tBest Loss: 0.977106\n",
      "14\tAccuracy: 63.33%\tLoss: 0.929329\tBest Loss: 0.929329\n",
      "15\tAccuracy: 66.67%\tLoss: 0.922735\tBest Loss: 0.922735\n",
      "16\tAccuracy: 63.33%\tLoss: 0.922297\tBest Loss: 0.922297\n",
      "17\tAccuracy: 56.67%\tLoss: 1.010944\tBest Loss: 0.922297\n",
      "18\tAccuracy: 63.33%\tLoss: 0.993307\tBest Loss: 0.922297\n",
      "19\tAccuracy: 70.00%\tLoss: 0.907809\tBest Loss: 0.907809\n",
      "20\tAccuracy: 66.67%\tLoss: 0.919785\tBest Loss: 0.907809\n",
      "21\tAccuracy: 60.00%\tLoss: 0.965662\tBest Loss: 0.907809\n",
      "22\tAccuracy: 56.67%\tLoss: 1.116327\tBest Loss: 0.907809\n",
      "23\tAccuracy: 60.00%\tLoss: 1.090862\tBest Loss: 0.907809\n",
      "24\tAccuracy: 70.00%\tLoss: 1.080940\tBest Loss: 0.907809\n",
      "25\tAccuracy: 63.33%\tLoss: 0.994273\tBest Loss: 0.907809\n",
      "26\tAccuracy: 63.33%\tLoss: 0.976294\tBest Loss: 0.907809\n",
      "27\tAccuracy: 63.33%\tLoss: 0.939702\tBest Loss: 0.907809\n",
      "28\tAccuracy: 60.00%\tLoss: 0.965749\tBest Loss: 0.907809\n",
      "29\tAccuracy: 60.00%\tLoss: 1.011184\tBest Loss: 0.907809\n",
      "30\tAccuracy: 53.33%\tLoss: 1.044007\tBest Loss: 0.907809\n",
      "31\tAccuracy: 63.33%\tLoss: 1.073835\tBest Loss: 0.907809\n",
      "32\tAccuracy: 63.33%\tLoss: 1.054433\tBest Loss: 0.907809\n",
      "33\tAccuracy: 60.00%\tLoss: 1.024633\tBest Loss: 0.907809\n",
      "34\tAccuracy: 60.00%\tLoss: 1.000770\tBest Loss: 0.907809\n",
      "35\tAccuracy: 66.67%\tLoss: 0.959198\tBest Loss: 0.907809\n",
      "36\tAccuracy: 70.00%\tLoss: 1.030414\tBest Loss: 0.907809\n",
      "37\tAccuracy: 63.33%\tLoss: 0.979915\tBest Loss: 0.907809\n",
      "38\tAccuracy: 60.00%\tLoss: 0.992612\tBest Loss: 0.907809\n",
      "Early Stopping!\n",
      "Total training time: 17.2s\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9.ckpt\n",
      "Accuracy for test: 64.37%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "early_stoping_threshold = 20\n",
    "best_loss = np.infty\n",
    "steps_from_best_loss = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver.restore(sess, \"./my_mnist_model_0_to_4_bn.ckpt\")\n",
    "        \n",
    "    t0 = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(len(X_train_5_to_9) // batch_size):\n",
    "            rdm_idx = np.random.permutation(len(X_train_5_to_9))\n",
    "            X_batch, y_batch = X_train_5_to_9[rdm_idx[:batch_size]], y_train_5_to_9[rdm_idx[:batch_size]]\n",
    "            sess.run(training_op_5_to_9, feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        loss_5_to_9_val, accuracy_5_to_9_val = sess.run([loss_5_to_9, accuracy_5_to_9], feed_dict={X: X_val_5_to_9, y: y_val_5_to_9})\n",
    "        \n",
    "        if (loss_5_to_9_val < best_loss):\n",
    "            saver_5_to_9.save(sess, \"./my_mnist_model_5_to_9.ckpt\")\n",
    "            best_loss = loss_5_to_9_val\n",
    "            steps_from_best_loss = 0\n",
    "        else:\n",
    "            steps_from_best_loss += 1\n",
    "            \n",
    "        if (steps_from_best_loss >= early_stoping_threshold):\n",
    "            print(\"Early Stopping!\")\n",
    "            break;\n",
    "\n",
    "        print(\"{}\\tAccuracy: {:.2f}%\\tLoss: {:.6f}\\tBest Loss: {:.6f}\".format(epoch, accuracy_5_to_9_val * 100, loss_5_to_9_val, best_loss))\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver_5_to_9.restore(sess, \"./my_mnist_model_5_to_9.ckpt\")\n",
    "    accuracy_5_to_9_test = sess.run(accuracy_5_to_9, feed_dict={X: X_test_5_to_9, y: y_test_5_to_9})\n",
    "    print(\"Accuracy for test: {:.2f}%\".format(accuracy_5_to_9_test*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caching lower layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_0_to_4_bn.ckpt\n",
      "0\tAccuracy: 40.00%\tLoss: 1.379673\tBest Loss: 1.379673\n",
      "1\tAccuracy: 53.33%\tLoss: 1.243368\tBest Loss: 1.243368\n",
      "2\tAccuracy: 43.33%\tLoss: 1.176059\tBest Loss: 1.176059\n",
      "3\tAccuracy: 60.00%\tLoss: 1.071881\tBest Loss: 1.071881\n",
      "4\tAccuracy: 53.33%\tLoss: 1.295100\tBest Loss: 1.071881\n",
      "5\tAccuracy: 46.67%\tLoss: 1.189524\tBest Loss: 1.071881\n",
      "6\tAccuracy: 50.00%\tLoss: 1.107791\tBest Loss: 1.071881\n",
      "7\tAccuracy: 56.67%\tLoss: 1.065170\tBest Loss: 1.065170\n",
      "8\tAccuracy: 46.67%\tLoss: 1.100391\tBest Loss: 1.065170\n",
      "9\tAccuracy: 53.33%\tLoss: 1.135660\tBest Loss: 1.065170\n",
      "10\tAccuracy: 46.67%\tLoss: 1.116057\tBest Loss: 1.065170\n",
      "11\tAccuracy: 50.00%\tLoss: 1.075023\tBest Loss: 1.065170\n",
      "12\tAccuracy: 56.67%\tLoss: 1.064219\tBest Loss: 1.064219\n",
      "13\tAccuracy: 53.33%\tLoss: 1.077805\tBest Loss: 1.064219\n",
      "14\tAccuracy: 53.33%\tLoss: 1.069044\tBest Loss: 1.064219\n",
      "15\tAccuracy: 46.67%\tLoss: 1.079646\tBest Loss: 1.064219\n",
      "16\tAccuracy: 56.67%\tLoss: 1.056279\tBest Loss: 1.056279\n",
      "17\tAccuracy: 60.00%\tLoss: 0.987984\tBest Loss: 0.987984\n",
      "18\tAccuracy: 60.00%\tLoss: 0.978806\tBest Loss: 0.978806\n",
      "19\tAccuracy: 60.00%\tLoss: 1.083736\tBest Loss: 0.978806\n",
      "20\tAccuracy: 60.00%\tLoss: 1.093090\tBest Loss: 0.978806\n",
      "21\tAccuracy: 53.33%\tLoss: 1.086623\tBest Loss: 0.978806\n",
      "22\tAccuracy: 46.67%\tLoss: 1.207907\tBest Loss: 0.978806\n",
      "23\tAccuracy: 50.00%\tLoss: 1.218338\tBest Loss: 0.978806\n",
      "24\tAccuracy: 60.00%\tLoss: 1.042401\tBest Loss: 0.978806\n",
      "25\tAccuracy: 63.33%\tLoss: 0.968936\tBest Loss: 0.968936\n",
      "26\tAccuracy: 60.00%\tLoss: 1.014168\tBest Loss: 0.968936\n",
      "27\tAccuracy: 63.33%\tLoss: 1.008699\tBest Loss: 0.968936\n",
      "28\tAccuracy: 60.00%\tLoss: 1.002775\tBest Loss: 0.968936\n",
      "29\tAccuracy: 63.33%\tLoss: 0.933693\tBest Loss: 0.933693\n",
      "30\tAccuracy: 70.00%\tLoss: 0.898117\tBest Loss: 0.898117\n",
      "31\tAccuracy: 63.33%\tLoss: 0.937793\tBest Loss: 0.898117\n",
      "32\tAccuracy: 60.00%\tLoss: 1.014595\tBest Loss: 0.898117\n",
      "33\tAccuracy: 66.67%\tLoss: 0.989777\tBest Loss: 0.898117\n",
      "34\tAccuracy: 66.67%\tLoss: 0.913587\tBest Loss: 0.898117\n",
      "35\tAccuracy: 63.33%\tLoss: 0.988047\tBest Loss: 0.898117\n",
      "36\tAccuracy: 60.00%\tLoss: 0.941102\tBest Loss: 0.898117\n",
      "37\tAccuracy: 60.00%\tLoss: 1.008963\tBest Loss: 0.898117\n",
      "38\tAccuracy: 56.67%\tLoss: 1.044701\tBest Loss: 0.898117\n",
      "39\tAccuracy: 53.33%\tLoss: 1.005257\tBest Loss: 0.898117\n",
      "40\tAccuracy: 66.67%\tLoss: 0.890189\tBest Loss: 0.890189\n",
      "41\tAccuracy: 70.00%\tLoss: 0.834644\tBest Loss: 0.834644\n",
      "42\tAccuracy: 70.00%\tLoss: 0.857216\tBest Loss: 0.834644\n",
      "43\tAccuracy: 63.33%\tLoss: 0.956090\tBest Loss: 0.834644\n",
      "44\tAccuracy: 56.67%\tLoss: 1.080537\tBest Loss: 0.834644\n",
      "45\tAccuracy: 53.33%\tLoss: 1.107941\tBest Loss: 0.834644\n",
      "46\tAccuracy: 56.67%\tLoss: 1.135583\tBest Loss: 0.834644\n",
      "47\tAccuracy: 53.33%\tLoss: 1.108575\tBest Loss: 0.834644\n",
      "48\tAccuracy: 56.67%\tLoss: 1.086276\tBest Loss: 0.834644\n",
      "49\tAccuracy: 60.00%\tLoss: 1.010859\tBest Loss: 0.834644\n",
      "50\tAccuracy: 56.67%\tLoss: 0.964523\tBest Loss: 0.834644\n",
      "51\tAccuracy: 50.00%\tLoss: 1.031397\tBest Loss: 0.834644\n",
      "52\tAccuracy: 50.00%\tLoss: 1.226434\tBest Loss: 0.834644\n",
      "53\tAccuracy: 46.67%\tLoss: 1.220614\tBest Loss: 0.834644\n",
      "54\tAccuracy: 53.33%\tLoss: 0.999008\tBest Loss: 0.834644\n",
      "55\tAccuracy: 53.33%\tLoss: 1.031584\tBest Loss: 0.834644\n",
      "56\tAccuracy: 53.33%\tLoss: 1.058657\tBest Loss: 0.834644\n",
      "57\tAccuracy: 60.00%\tLoss: 0.984296\tBest Loss: 0.834644\n",
      "58\tAccuracy: 63.33%\tLoss: 0.911255\tBest Loss: 0.834644\n",
      "59\tAccuracy: 63.33%\tLoss: 0.930083\tBest Loss: 0.834644\n",
      "60\tAccuracy: 56.67%\tLoss: 0.990134\tBest Loss: 0.834644\n",
      "Early Stopping!\n",
      "Total training time: 21.5s\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_cache.ckpt\n",
      "Accuracy for test: 67.93%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "early_stoping_threshold = 20\n",
    "best_loss = np.infty\n",
    "steps_from_best_loss = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver.restore(sess, \"./my_mnist_model_0_to_4_bn.ckpt\")\n",
    "    t0 = time.time()\n",
    "    \n",
    "    hidden5_train_cache = sess.run(hidden_5_to_9, feed_dict={X: X_train_5_to_9, y: y_train_5_to_9})\n",
    "    hidden5_val_cache = sess.run(hidden_5_to_9, feed_dict={X: X_val_5_to_9, y: y_val_5_to_9})\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(len(hidden5_train_cache) // batch_size):\n",
    "            rdm_idx = np.random.permutation(len(hidden5_train_cache))\n",
    "            X_batch, y_batch = hidden5_train_cache[rdm_idx[:batch_size]], y_train_5_to_9[rdm_idx[:batch_size]]\n",
    "            sess.run(training_op_5_to_9, feed_dict={hidden_5_to_9: X_batch, y: y_batch})\n",
    "        \n",
    "        loss_5_to_9_val, accuracy_5_to_9_val = sess.run([loss_5_to_9, accuracy_5_to_9], feed_dict={hidden_5_to_9: hidden5_val_cache, y: y_val_5_to_9})\n",
    "        \n",
    "        if (loss_5_to_9_val < best_loss):\n",
    "            saver_5_to_9.save(sess, \"./my_mnist_model_5_to_9_cache.ckpt\")\n",
    "            best_loss = loss_5_to_9_val\n",
    "            steps_from_best_loss = 0\n",
    "        else:\n",
    "            steps_from_best_loss += 1\n",
    "            \n",
    "        if (steps_from_best_loss >= early_stoping_threshold):\n",
    "            print(\"Early Stopping!\")\n",
    "            break;\n",
    "\n",
    "        print(\"{}\\tAccuracy: {:.2f}%\\tLoss: {:.6f}\\tBest Loss: {:.6f}\".format(epoch, accuracy_5_to_9_val * 100, loss_5_to_9_val, best_loss))\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "    \n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    saver_5_to_9.restore(sess, \"./my_mnist_model_5_to_9_cache.ckpt\")\n",
    "    accuracy_5_to_9_test = sess.run(accuracy_5_to_9, feed_dict={X: X_test_5_to_9, y: y_test_5_to_9})\n",
    "    print(\"Accuracy for test: {:.2f}%\".format(accuracy_5_to_9_test*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using only 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./my_mnist_model_0_to_4_bn.ckpt.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "# DNN\n",
    "hidden_5_to_9 = tf.get_default_graph().get_tensor_by_name(\"dnn_0_to_4_bn/dnn_0_to_4_bn_dnn/hidden4_out:0\")\n",
    "logits_5_to_9 = tf.layers.dense(hidden_5_to_9, 5, name=\"logits_5_to_9\", kernel_initializer=he_init)\n",
    "\n",
    "# Loss\n",
    "xentropy_5_to_9 = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_5_to_9, labels=y)\n",
    "loss_5_to_9 = tf.reduce_mean(xentropy_5_to_9, name=\"loss_5_to_9\")\n",
    "\n",
    "# Train\n",
    "trainable_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"hidden[34]|logits_5_to_9\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_5_9)\n",
    "training_op_5_to_9 = optimizer.minimize(loss_5_to_9, var_list=trainable_variables, name=\"training_op_5_to_9\")\n",
    "\n",
    "# Eval\n",
    "correct = tf.nn.in_top_k(logits_5_to_9, y, 1)\n",
    "accuracy_5_to_9 = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy_5_to_9\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver_5_to_9 = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_0_to_4_bn.ckpt\n",
      "0\tAccuracy: 43.33%\tLoss: 1.362749\tBest Loss: 1.362749\n",
      "1\tAccuracy: 46.67%\tLoss: 1.084748\tBest Loss: 1.084748\n",
      "2\tAccuracy: 56.67%\tLoss: 1.011841\tBest Loss: 1.011841\n",
      "3\tAccuracy: 53.33%\tLoss: 0.985958\tBest Loss: 0.985958\n",
      "4\tAccuracy: 60.00%\tLoss: 0.992126\tBest Loss: 0.985958\n",
      "5\tAccuracy: 53.33%\tLoss: 1.067675\tBest Loss: 0.985958\n",
      "6\tAccuracy: 50.00%\tLoss: 1.064475\tBest Loss: 0.985958\n",
      "7\tAccuracy: 56.67%\tLoss: 1.043837\tBest Loss: 0.985958\n",
      "8\tAccuracy: 60.00%\tLoss: 1.054271\tBest Loss: 0.985958\n",
      "9\tAccuracy: 60.00%\tLoss: 1.026646\tBest Loss: 0.985958\n",
      "10\tAccuracy: 63.33%\tLoss: 0.998456\tBest Loss: 0.985958\n",
      "11\tAccuracy: 56.67%\tLoss: 0.965752\tBest Loss: 0.965752\n",
      "12\tAccuracy: 63.33%\tLoss: 0.862083\tBest Loss: 0.862083\n",
      "13\tAccuracy: 70.00%\tLoss: 0.822880\tBest Loss: 0.822880\n",
      "14\tAccuracy: 66.67%\tLoss: 0.886024\tBest Loss: 0.822880\n",
      "15\tAccuracy: 60.00%\tLoss: 0.926282\tBest Loss: 0.822880\n",
      "16\tAccuracy: 60.00%\tLoss: 0.964440\tBest Loss: 0.822880\n",
      "17\tAccuracy: 66.67%\tLoss: 0.926856\tBest Loss: 0.822880\n",
      "18\tAccuracy: 66.67%\tLoss: 0.921739\tBest Loss: 0.822880\n",
      "19\tAccuracy: 63.33%\tLoss: 0.950158\tBest Loss: 0.822880\n",
      "20\tAccuracy: 66.67%\tLoss: 0.915768\tBest Loss: 0.822880\n",
      "21\tAccuracy: 73.33%\tLoss: 0.816187\tBest Loss: 0.816187\n",
      "22\tAccuracy: 70.00%\tLoss: 0.793203\tBest Loss: 0.793203\n",
      "23\tAccuracy: 60.00%\tLoss: 0.981155\tBest Loss: 0.793203\n",
      "24\tAccuracy: 60.00%\tLoss: 1.048280\tBest Loss: 0.793203\n",
      "25\tAccuracy: 70.00%\tLoss: 1.056258\tBest Loss: 0.793203\n",
      "26\tAccuracy: 66.67%\tLoss: 1.103961\tBest Loss: 0.793203\n",
      "27\tAccuracy: 60.00%\tLoss: 1.018491\tBest Loss: 0.793203\n",
      "28\tAccuracy: 70.00%\tLoss: 0.896204\tBest Loss: 0.793203\n",
      "29\tAccuracy: 73.33%\tLoss: 0.778221\tBest Loss: 0.778221\n",
      "30\tAccuracy: 66.67%\tLoss: 0.792526\tBest Loss: 0.778221\n",
      "31\tAccuracy: 63.33%\tLoss: 0.899141\tBest Loss: 0.778221\n",
      "32\tAccuracy: 60.00%\tLoss: 0.985416\tBest Loss: 0.778221\n",
      "33\tAccuracy: 63.33%\tLoss: 0.969032\tBest Loss: 0.778221\n",
      "34\tAccuracy: 66.67%\tLoss: 0.925444\tBest Loss: 0.778221\n",
      "35\tAccuracy: 63.33%\tLoss: 0.960400\tBest Loss: 0.778221\n",
      "36\tAccuracy: 63.33%\tLoss: 0.958840\tBest Loss: 0.778221\n",
      "37\tAccuracy: 70.00%\tLoss: 0.917515\tBest Loss: 0.778221\n",
      "38\tAccuracy: 63.33%\tLoss: 0.907126\tBest Loss: 0.778221\n",
      "39\tAccuracy: 63.33%\tLoss: 0.902203\tBest Loss: 0.778221\n",
      "40\tAccuracy: 63.33%\tLoss: 0.894544\tBest Loss: 0.778221\n",
      "41\tAccuracy: 63.33%\tLoss: 0.830982\tBest Loss: 0.778221\n",
      "42\tAccuracy: 70.00%\tLoss: 0.787377\tBest Loss: 0.778221\n",
      "43\tAccuracy: 70.00%\tLoss: 0.814719\tBest Loss: 0.778221\n",
      "44\tAccuracy: 70.00%\tLoss: 0.801015\tBest Loss: 0.778221\n",
      "45\tAccuracy: 66.67%\tLoss: 0.863876\tBest Loss: 0.778221\n",
      "46\tAccuracy: 66.67%\tLoss: 0.875250\tBest Loss: 0.778221\n",
      "47\tAccuracy: 70.00%\tLoss: 0.809262\tBest Loss: 0.778221\n",
      "48\tAccuracy: 66.67%\tLoss: 0.830624\tBest Loss: 0.778221\n",
      "Early Stopping!\n",
      "Total training time: 15.8s\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_four_layers.ckpt\n",
      "Accuracy for test: 69.43%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "early_stoping_threshold = 20\n",
    "best_loss = np.infty\n",
    "steps_from_best_loss = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver.restore(sess, \"./my_mnist_model_0_to_4_bn.ckpt\")\n",
    "        \n",
    "    t0 = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(len(X_train_5_to_9) // batch_size):\n",
    "            rdm_idx = np.random.permutation(len(X_train_5_to_9))\n",
    "            X_batch, y_batch = X_train_5_to_9[rdm_idx[:batch_size]], y_train_5_to_9[rdm_idx[:batch_size]]\n",
    "            sess.run(training_op_5_to_9, feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        loss_5_to_9_val, accuracy_5_to_9_val = sess.run([loss_5_to_9, accuracy_5_to_9], feed_dict={X: X_val_5_to_9, y: y_val_5_to_9})\n",
    "        \n",
    "        if (loss_5_to_9_val < best_loss):\n",
    "            saver_5_to_9.save(sess, \"./my_mnist_model_5_to_9_four_layers.ckpt\")\n",
    "            best_loss = loss_5_to_9_val\n",
    "            steps_from_best_loss = 0\n",
    "        else:\n",
    "            steps_from_best_loss += 1\n",
    "            \n",
    "        if (steps_from_best_loss >= early_stoping_threshold):\n",
    "            print(\"Early Stopping!\")\n",
    "            break;\n",
    "\n",
    "        print(\"{}\\tAccuracy: {:.2f}%\\tLoss: {:.6f}\\tBest Loss: {:.6f}\".format(epoch, accuracy_5_to_9_val * 100, loss_5_to_9_val, best_loss))\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "with tf.Session() as sess:\n",
    "    saver_5_to_9.restore(sess, \"./my_mnist_model_5_to_9_four_layers.ckpt\")\n",
    "    accuracy_5_to_9_test = sess.run(accuracy_5_to_9, feed_dict={X: X_test_5_to_9, y: y_test_5_to_9})\n",
    "    print(\"Accuracy for test: {:.2f}%\".format(accuracy_5_to_9_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name=\"training\")\n",
    "\n",
    "# DNN\n",
    "dnn_outputs = dnn(X, n_layers=5, n_neurons=140, training=training, name=\"dnn_5_to_9\")\n",
    "logits_5_to_9 = tf.layers.dense(dnn_outputs, 5, name=\"logits_5_to_9\", kernel_initializer=he_init)\n",
    "\n",
    "# Loss\n",
    "xentropy_5_to_9 = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_5_to_9, labels=y)\n",
    "loss_5_to_9 = tf.reduce_mean(xentropy_5_to_9, name=\"loss_5_to_9\")\n",
    "\n",
    "# Train\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_5_9)\n",
    "training_op_5_to_9 = optimizer.minimize(loss_5_to_9, name=\"training_op_5_to_9\")\n",
    "\n",
    "# Eval\n",
    "correct = tf.nn.in_top_k(logits_5_to_9, y, 1)\n",
    "accuracy_5_to_9 = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy_5_to_9\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver_5_to_9 = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tAccuracy: 50.00%\tLoss: 8.320246\tBest Loss: 8.320246\n",
      "1\tAccuracy: 83.33%\tLoss: 0.344862\tBest Loss: 0.344862\n",
      "2\tAccuracy: 70.00%\tLoss: 1.861371\tBest Loss: 0.344862\n",
      "3\tAccuracy: 63.33%\tLoss: 2.058497\tBest Loss: 0.344862\n",
      "4\tAccuracy: 90.00%\tLoss: 0.294264\tBest Loss: 0.294264\n",
      "5\tAccuracy: 86.67%\tLoss: 0.379326\tBest Loss: 0.294264\n",
      "6\tAccuracy: 90.00%\tLoss: 0.316537\tBest Loss: 0.294264\n",
      "7\tAccuracy: 90.00%\tLoss: 0.244286\tBest Loss: 0.244286\n",
      "8\tAccuracy: 86.67%\tLoss: 0.592166\tBest Loss: 0.244286\n",
      "9\tAccuracy: 80.00%\tLoss: 0.861799\tBest Loss: 0.244286\n",
      "10\tAccuracy: 83.33%\tLoss: 0.791724\tBest Loss: 0.244286\n",
      "11\tAccuracy: 90.00%\tLoss: 0.517244\tBest Loss: 0.244286\n",
      "12\tAccuracy: 83.33%\tLoss: 0.960161\tBest Loss: 0.244286\n",
      "13\tAccuracy: 86.67%\tLoss: 0.639712\tBest Loss: 0.244286\n",
      "14\tAccuracy: 96.67%\tLoss: 0.280998\tBest Loss: 0.244286\n",
      "15\tAccuracy: 90.00%\tLoss: 0.342864\tBest Loss: 0.244286\n",
      "16\tAccuracy: 86.67%\tLoss: 0.704786\tBest Loss: 0.244286\n",
      "17\tAccuracy: 86.67%\tLoss: 0.888516\tBest Loss: 0.244286\n",
      "18\tAccuracy: 86.67%\tLoss: 0.976676\tBest Loss: 0.244286\n",
      "19\tAccuracy: 86.67%\tLoss: 0.957066\tBest Loss: 0.244286\n",
      "20\tAccuracy: 90.00%\tLoss: 0.942416\tBest Loss: 0.244286\n",
      "21\tAccuracy: 90.00%\tLoss: 0.846739\tBest Loss: 0.244286\n",
      "22\tAccuracy: 83.33%\tLoss: 1.640255\tBest Loss: 0.244286\n",
      "23\tAccuracy: 80.00%\tLoss: 1.572788\tBest Loss: 0.244286\n",
      "24\tAccuracy: 86.67%\tLoss: 0.683420\tBest Loss: 0.244286\n",
      "25\tAccuracy: 80.00%\tLoss: 0.953528\tBest Loss: 0.244286\n",
      "26\tAccuracy: 76.67%\tLoss: 1.988855\tBest Loss: 0.244286\n",
      "Early Stopping!\n",
      "Total training time: 2.2s\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_scratch.ckpt\n",
      "Accuracy for test: 81.63%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "early_stoping_threshold = 20\n",
    "best_loss = np.infty\n",
    "steps_from_best_loss = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    t0 = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(len(X_train_5_to_9) // batch_size):\n",
    "            rdm_idx = np.random.permutation(len(X_train_5_to_9))\n",
    "            X_batch, y_batch = X_train_5_to_9[rdm_idx[:batch_size]], y_train_5_to_9[rdm_idx[:batch_size]]\n",
    "            sess.run(training_op_5_to_9, feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        loss_5_to_9_val, accuracy_5_to_9_val = sess.run([loss_5_to_9, accuracy_5_to_9], feed_dict={X: X_val_5_to_9, y: y_val_5_to_9})\n",
    "        \n",
    "        if (loss_5_to_9_val < best_loss):\n",
    "            saver_5_to_9.save(sess, \"./my_mnist_model_5_to_9_scratch.ckpt\")\n",
    "            best_loss = loss_5_to_9_val\n",
    "            steps_from_best_loss = 0\n",
    "        else:\n",
    "            steps_from_best_loss += 1\n",
    "            \n",
    "        if (steps_from_best_loss >= early_stoping_threshold):\n",
    "            print(\"Early Stopping!\")\n",
    "            break;\n",
    "\n",
    "        print(\"{}\\tAccuracy: {:.2f}%\\tLoss: {:.6f}\\tBest Loss: {:.6f}\".format(epoch, accuracy_5_to_9_val * 100, loss_5_to_9_val, best_loss))\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "with tf.Session() as sess:\n",
    "    saver_5_to_9.restore(sess, \"./my_mnist_model_5_to_9_scratch.ckpt\")\n",
    "    accuracy_5_to_9_test = sess.run(accuracy_5_to_9, feed_dict={X: X_test_5_to_9, y: y_test_5_to_9})\n",
    "    print(\"Accuracy for test: {:.2f}%\".format(accuracy_5_to_9_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
